"""Configuration files for safe reinforcement learning."""

# Default configuration
defaults:
  - _self_

# Environment configuration
env:
  name: "CartPole-v1"
  safety_threshold: 2.0
  velocity_threshold: 3.0
  safety_penalty: -10.0

# Algorithm configuration
algorithm:
  name: "safe_qlearning"  # Options: safe_qlearning, cpo, lagrangian
  learning_rate: 0.001
  gamma: 0.99
  lam: 0.95
  clip_ratio: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  cost_limit: 0.01
  cpo_iters: 10
  cpo_step_size: 0.01
  lagrangian_lr: 1e-3
  hidden_dims: [256, 256]
  
  # Q-learning specific
  epsilon: 1.0
  epsilon_decay: 0.995
  epsilon_min: 0.01

# Training configuration
training:
  num_episodes: 1000
  log_interval: 100
  eval_interval: 200
  save_interval: 500
  batch_size: 64
  buffer_size: 10000

# Evaluation configuration
evaluation:
  num_episodes: 100
  alpha: 0.05  # CVaR risk level

# Output configuration
output_dir: "outputs"
seed: 42
